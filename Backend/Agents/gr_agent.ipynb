{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7ce7630c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph,START,END\n",
    "from langchain_groq import ChatGroq\n",
    "from typing import TypedDict,Annotated\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from dotenv import load_dotenv\n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b63dfadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class base_state(TypedDict):\n",
    "    query:str\n",
    "    gr_rem:str\n",
    "    final_prompt:str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a82449c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File exists: False\n",
      "Absolute path: /content/Backend/Agents/.env\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7f3b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "def get_llm():\n",
    "    llm= ChatGroq(api_key=os.getenv(\"GROQ_API_KEY\"),temperature=0.5,model=\"openai/gpt-oss-120b\")\n",
    "    return llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6d77ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def grammer(state:base_state):\n",
    "    \"remove grammer mistake from query\"\n",
    "    prompt = PromptTemplate(\n",
    "        input_variables=[\"query\"],\n",
    "        template=\"\"\" \n",
    "        clean the following prompt\n",
    "      remove the grammer_mistake and make it clear\n",
    "\n",
    "query:\n",
    "{query}\n",
    "\n",
    "\"\"\"\n",
    "    )\n",
    "    llm =  get_llm()\n",
    "    chain=  prompt | llm | StrOutputParser()\n",
    "\n",
    "    result =   await chain.ainvoke({\n",
    "        \"query\":state[\"query\"]\n",
    "    })\n",
    "    return {\n",
    "        \"gr_rem\":result\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88fd8ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def prompt_enh(state:base_state):\n",
    "    \"enhance the  prompt \"\n",
    "    prompt = PromptTemplate(\n",
    "        input_variables=[\"gr_rem\"],\n",
    "        template=\"\"\" \n",
    "Task:\n",
    "You are a prompt engineering expert. Your goal is to transform the Input Prompt into three distinct, high-quality prompt versions, each clearly labeled and written in professional, precise language.\n",
    "\n",
    "Input:\n",
    "{gr_rem}\n",
    "\n",
    "Requirements:\n",
    "\n",
    "Rewrite the input prompt; do not answer or execute it.\n",
    "\n",
    "Each version must be self-contained, unambiguous, and optimized for use with an LLM.\n",
    "\n",
    "Use clear structure, explicit instructions, and strong constraints.\n",
    "\n",
    "Maintain the original intent of {gr_rem} while improving clarity and effectiveness.\n",
    "\n",
    "Deliverables (provide all three):\n",
    "\n",
    "Detailed Prompt\n",
    "\n",
    "Multiple paragraphs\n",
    "\n",
    "Clearly state the objective, context, constraints, assumptions, and expected output\n",
    "\n",
    "Include formatting or style requirements if relevant\n",
    "\n",
    "Concise Prompt\n",
    "\n",
    "A shorter, highly focused version\n",
    "\n",
    "Retains the core objective and key constraints\n",
    "\n",
    "Optimized for quick use while remaining precise\n",
    "\n",
    "Instructional Prompt\n",
    "\n",
    "Written as step-by-step instructions to the model\n",
    "\n",
    "Emphasizes process, reasoning expectations, and output structure\n",
    "\n",
    "Output Format (use exactly this structure):\n",
    "\n",
    "Detailed Prompt:\n",
    "<your detailed prompt here>\n",
    "\n",
    "Concise Prompt:\n",
    "<your concise prompt here>\n",
    "\n",
    "Instructional Prompt:\n",
    "<your instructional prompt here> \n",
    "\n",
    "\"\"\"\n",
    "    )\n",
    "    llm =  get_llm()\n",
    "    chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "    result = await chain.ainvoke({\n",
    "        \"gr_rem\":state[\"gr_rem\"]\n",
    "    })\n",
    "    return {\n",
    "        \"final_prompt\":result\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8992376",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph= StateGraph(base_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa198f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x79e9cf472cc0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.add_node(\"mistake_remover\",grammer)\n",
    "graph.add_node(\"prompt_enhancer\",prompt_enh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545d49d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.add_edge(START,\"mistake_remover\")\n",
    "graph.add_edge(\"mistake_remover\",\"prompt_enhancer\")\n",
    "graph.add_edge(\"prompt_enhancer\",END)\n",
    "\n",
    "agent = graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc00698f",
   "metadata": {},
   "outputs": [],
   "source": [
    "intial_state={\n",
    "    \"query\":\"what is jwt\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0df9e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070c6297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Cleaned Prompt**\n",
      "\n",
      "Please clean the following prompt by removing any grammatical mistakes and making it clear.\n",
      "\n",
      "**Query:**  \n",
      "What is JWT?**Detailed Prompt:**  \n",
      "You are an expert editor tasked with refining a user‑submitted prompt.  \n",
      "\n",
      "**Objective:** Rewrite the supplied prompt so that it is free of grammatical errors, unambiguous, and maximally clear, while preserving its original intent.  \n",
      "\n",
      "**Context:** The original prompt asks the model to “clean the following prompt by removing any grammatical mistakes and making it clear.” The embedded query to be cleaned is:  \n",
      "\n",
      "```\n",
      "What is JWT?\n",
      "```  \n",
      "\n",
      "**Constraints:**  \n",
      "1. Do not answer the query “What is JWT?” – only edit the surrounding instruction.  \n",
      "2. Preserve the structure of the original request (i.e., a brief instruction followed by the query).  \n",
      "3. Maintain a professional tone and use standard English grammar.  \n",
      "4. Keep the cleaned prompt concise but fully understandable.  \n",
      "\n",
      "**Assumptions:** The user expects the cleaned prompt to be ready for immediate use with a language model.  \n",
      "\n",
      "**Expected Output:**  \n",
      "- A single, polished version of the original prompt.  \n",
      "- The output should be presented as plain text, with the instruction line first and the query on a separate line, exactly as in the original format.  \n",
      "\n",
      "**Formatting Requirements:**  \n",
      "```\n",
      "Please clean the following prompt by removing any grammatical mistakes and making it clear.\n",
      "\n",
      "Query:\n",
      "What is JWT?\n",
      "```  \n",
      "\n",
      "Provide the revised version adhering to the constraints above.  \n",
      "\n",
      "---\n",
      "\n",
      "**Concise Prompt:**  \n",
      "Edit the following prompt for grammar and clarity without answering the query. Preserve the instruction‑query format.\n",
      "\n",
      "```\n",
      "Please clean the following prompt by removing any grammatical mistakes and making it clear.\n",
      "\n",
      "Query:\n",
      "What is JWT?\n",
      "```  \n",
      "\n",
      "Return the cleaned version only.  \n",
      "\n",
      "---\n",
      "\n",
      "**Instructional Prompt:**  \n",
      "1. Read the supplied prompt.  \n",
      "2. Identify and correct any grammatical or typographical errors.  \n",
      "3. Ensure the instruction is explicit, unambiguous, and maintains a professional tone.  \n",
      "4. Keep the original layout: an instruction line followed by “Query:” and the question.  \n",
      "5. Do **not** provide an answer to the question “What is JWT?” – only return the revised prompt.  \n",
      "\n",
      "Output the cleaned prompt exactly as plain text."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431966a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
